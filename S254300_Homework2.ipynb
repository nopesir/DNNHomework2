{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "S254300 - Homework2",
      "provenance": [],
      "collapsed_sections": [
        "fo942LMOdlh4",
        "CLJd0LwpT6eK",
        "9gwii0TBHvzh",
        "2qYIHPzYLY7i",
        "FYEDQ7Z21ldN",
        "gbZ1t5Qs2z4j",
        "KEyL3H_R4qCf",
        "AxYUli9d9uYQ",
        "UsHFI-GAJd69"
      ],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9QcGnGPdX2C",
        "colab_type": "text"
      },
      "source": [
        "### **Install requirements**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k9O3aM3Tb28q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Colab URL: https://colab.research.google.com/drive/1Lbxl_3lu1E1uxJKjm_acQkgXqBvjFbsN#scrollTo=LjX6UizGdU3K\n",
        "\n",
        "!pip3 install 'torch'\n",
        "!pip3 install 'torchvision'\n",
        "!pip3 install 'Pillow-SIMD'\n",
        "!pip3 install 'utils'\n",
        "!pip3 install 'livelossplot'\n",
        "!pip3 install 'tqdm'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fo942LMOdlh4",
        "colab_type": "text"
      },
      "source": [
        "### **Import libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DokFOdD1dJEl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import logging\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Subset, DataLoader, random_split, Sampler, ConcatDataset\n",
        "from torch.backends import cudnn\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torchvision.models import alexnet, resnext101_32x8d, inception_v3\n",
        "from torchvision.models.inception import InceptionAux\n",
        "from torchvision.datasets import VisionDataset\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "from pandas import read_csv\n",
        "import copy\n",
        "from livelossplot import PlotLosses\n",
        "import os.path\n",
        "import sys\n",
        "import numpy as np\n",
        "from torchvision import datasets\n",
        "from torch.utils.data.sampler import SubsetRandomSampler"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CLJd0LwpT6eK",
        "colab_type": "text"
      },
      "source": [
        "### **Constant definition**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "dcdf07e0-4852-4cdf-8e7d-f555bc63ee60",
        "cellView": "code",
        "id": "hmnoZryKTbWX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print('Device is: ' + DEVICE)\n",
        "\n",
        "NUM_CLASSES = 101    # 101 + 1: There is am extra Background class that should be removed \n",
        "LOG_FREQUENCY = 5\n",
        "\n",
        "# Epochs after which the graphs draw the updated logs\n",
        "FREQDRAW = 2\n",
        "\n",
        "\n",
        "\n",
        "# inception_v3 hyperparameters (below all the parameters used in the Homework)\n",
        "BATCH_SIZE = 50     # Higher batch sizes allows for larger learning rates. An empirical heuristic suggests that, when changing\n",
        "                     # the batch size, learning rate should change by the same factor to have comparable results\n",
        "LR = 3e-3            # The initial Learning Rate\n",
        "MOMENTUM = 0.9       # Hyperparameter for SGD, keep this at 0.9 when using SGD\n",
        "WEIGHT_DECAY = 5e-5  # Regularization, you can keep this at the default\n",
        "NUM_EPOCHS = 15      # Total number of training epochs (iterations over dataset)\n",
        "STEP_SIZE = 13       # How many epochs before decreasing learning rate (if using a step-down policy)\n",
        "GAMMA = 0.5          # Multiplicative factor for learning rate step-down\n",
        "\n",
        "\n",
        "'''\n",
        "# 2C 1st hyperparameters\n",
        "BATCH_SIZE = 964     # Higher batch sizes allows for larger learning rates. An empirical heuristic suggests that, when changing\n",
        "                     # the batch size, learning rate should change by the same factor to have comparable results\n",
        "LR = 1e-1            # The initial Learning Rate\n",
        "MOMENTUM = 0.9       # Hyperparameter for SGD, keep this at 0.9 when using SGD\n",
        "WEIGHT_DECAY = 5e-5  # Regularization, you can keep this at the default\n",
        "NUM_EPOCHS = 30      # Total number of training epochs (iterations over dataset)\n",
        "STEP_SIZE = 10       # How many epochs before decreasing learning rate (if using a step-down policy)\n",
        "GAMMA = 0.6          # Multiplicative factor for learning rate step-down\n",
        "\n",
        "# 2C 2nd hyperparameters\n",
        "BATCH_SIZE = 964     # Higher batch sizes allows for larger learning rates. An empirical heuristic suggests that, when changing\n",
        "                     # the batch size, learning rate should change by the same factor to have comparable results\n",
        "LR = 7e-2            # The initial Learning Rate\n",
        "MOMENTUM = 0.9       # Hyperparameter for SGD, keep this at 0.9 when using SGD\n",
        "WEIGHT_DECAY = 5e-5  # Regularization, you can keep this at the default\n",
        "NUM_EPOCHS = 40      # Total number of training epochs (iterations over dataset)\n",
        "STEP_SIZE = 10       # How many epochs before decreasing learning rate (if using a step-down policy)\n",
        "GAMMA = 0.9          # Multiplicative factor for learning rate step-down\n",
        "\n",
        "\n",
        "# 3C 1st hyperparameters\n",
        "BATCH_SIZE = 964     # Higher batch sizes allows for larger learning rates. An empirical heuristic suggests that, when changing\n",
        "                     # the batch size, learning rate should change by the same factor to have comparable results\n",
        "LR = 5e-3            # The initial Learning Rate\n",
        "MOMENTUM = 0.9       # Hyperparameter for SGD, keep this at 0.9 when using SGD\n",
        "WEIGHT_DECAY = 5e-5  # Regularization, you can keep this at the default\n",
        "NUM_EPOCHS = 30      # Total number of training epochs (iterations over dataset)\n",
        "STEP_SIZE = 25       # How many epochs before decreasing learning rate (if using a step-down policy)\n",
        "GAMMA = 0.5          # Multiplicative factor for learning rate step-down\n",
        "\n",
        "# 3C 2nd hyperparameters and 3D and 3E\n",
        "BATCH_SIZE = 964     # Higher batch sizes allows for larger learning rates. An empirical heuristic suggests that, when changing\n",
        "                     # the batch size, learning rate should change by the same factor to have comparable results\n",
        "LR = 2e-2            # The initial Learning Rate\n",
        "MOMENTUM = 0.9       # Hyperparameter for SGD, keep this at 0.9 when using SGD\n",
        "WEIGHT_DECAY = 5e-5  # Regularization, you can keep this at the default\n",
        "NUM_EPOCHS = 30      # Total number of training epochs (iterations over dataset)\n",
        "STEP_SIZE = 25       # How many epochs before decreasing learning rate (if using a step-down policy)\n",
        "GAMMA = 0.5          # Multiplicative factor for learning rate step-down\n",
        "\n",
        "# 3C 3rd hyperparameters\n",
        "BATCH_SIZE = 964     # Higher batch sizes allows for larger learning rates. An empirical heuristic suggests that, when changing\n",
        "                     # the batch size, learning rate should change by the same factor to have comparable results\n",
        "LR = 2e-3            # The initial Learning Rate\n",
        "MOMENTUM = 0.9       # Hyperparameter for SGD, keep this at 0.9 when using SGD\n",
        "WEIGHT_DECAY = 5e-5  # Regularization, you can keep this at the default\n",
        "NUM_EPOCHS = 40      # Total number of training epochs (iterations over dataset)\n",
        "STEP_SIZE = 10       # How many epochs before decreasing learning rate (if using a step-down policy)\n",
        "GAMMA = 0.5          # Multiplicative factor for learning rate step-down\n",
        "\n",
        "\n",
        "# resnext101_32x8d hyperparameters\n",
        "BATCH_SIZE = 50     # Higher batch sizes allows for larger learning rates. An empirical heuristic suggests that, when changing\n",
        "                     # the batch size, learning rate should change by the same factor to have comparable results\n",
        "LR = 4e-4            # The initial Learning Rate\n",
        "MOMENTUM = 0.9       # Hyperparameter for SGD, keep this at 0.9 when using SGD\n",
        "WEIGHT_DECAY = 5e-5  # Regularization, you can keep this at the default\n",
        "NUM_EPOCHS = 20      # Total number of training epochs (iterations over dataset)\n",
        "STEP_SIZE = 18       # How many epochs before decreasing learning rate (if using a step-down policy)\n",
        "GAMMA = 0.5          # Multiplicative factor for learning rate step-down\n",
        "\n",
        "# inception_v3 hyperparameters\n",
        "BATCH_SIZE = 50     # Higher batch sizes allows for larger learning rates. An empirical heuristic suggests that, when changing\n",
        "                     # the batch size, learning rate should change by the same factor to have comparable results\n",
        "LR = 3e-3            # The initial Learning Rate\n",
        "MOMENTUM = 0.9       # Hyperparameter for SGD, keep this at 0.9 when using SGD\n",
        "WEIGHT_DECAY = 5e-5  # Regularization, you can keep this at the default\n",
        "NUM_EPOCHS = 15      # Total number of training epochs (iterations over dataset)\n",
        "STEP_SIZE = 13       # How many epochs before decreasing learning rate (if using a step-down policy)\n",
        "GAMMA = 0.5          # Multiplicative factor for learning rate step-down\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Device is: cuda\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n# 2C 1st hyperparameters\\nBATCH_SIZE = 964     # Higher batch sizes allows for larger learning rates. An empirical heuristic suggests that, when changing\\n                     # the batch size, learning rate should change by the same factor to have comparable results\\nLR = 1e-1            # The initial Learning Rate\\nMOMENTUM = 0.9       # Hyperparameter for SGD, keep this at 0.9 when using SGD\\nWEIGHT_DECAY = 5e-5  # Regularization, you can keep this at the default\\nNUM_EPOCHS = 30      # Total number of training epochs (iterations over dataset)\\nSTEP_SIZE = 10       # How many epochs before decreasing learning rate (if using a step-down policy)\\nGAMMA = 0.6          # Multiplicative factor for learning rate step-down\\n\\n# 2C 2nd hyperparameters\\nBATCH_SIZE = 964     # Higher batch sizes allows for larger learning rates. An empirical heuristic suggests that, when changing\\n                     # the batch size, learning rate should change by the same factor to have comparable results\\nLR = 7e-2            # The initial Learning Rate\\nMOMENTUM = 0.9       # Hyperparameter for SGD, keep this at 0.9 when using SGD\\nWEIGHT_DECAY = 5e-5  # Regularization, you can keep this at the default\\nNUM_EPOCHS = 40      # Total number of training epochs (iterations over dataset)\\nSTEP_SIZE = 10       # How many epochs before decreasing learning rate (if using a step-down policy)\\nGAMMA = 0.9          # Multiplicative factor for learning rate step-down\\n\\n\\n# 3C 1st hyperparameters\\nBATCH_SIZE = 964     # Higher batch sizes allows for larger learning rates. An empirical heuristic suggests that, when changing\\n                     # the batch size, learning rate should change by the same factor to have comparable results\\nLR = 5e-3            # The initial Learning Rate\\nMOMENTUM = 0.9       # Hyperparameter for SGD, keep this at 0.9 when using SGD\\nWEIGHT_DECAY = 5e-5  # Regularization, you can keep this at the default\\nNUM_EPOCHS = 30      # Total number of training epochs (iterations over dataset)\\nSTEP_SIZE = 25       # How many epochs before decreasing learning rate (if using a step-down policy)\\nGAMMA = 0.5          # Multiplicative factor for learning rate step-down\\n\\n# 3C 2nd hyperparameters and 3D and 3E\\nBATCH_SIZE = 964     # Higher batch sizes allows for larger learning rates. An empirical heuristic suggests that, when changing\\n                     # the batch size, learning rate should change by the same factor to have comparable results\\nLR = 2e-2            # The initial Learning Rate\\nMOMENTUM = 0.9       # Hyperparameter for SGD, keep this at 0.9 when using SGD\\nWEIGHT_DECAY = 5e-5  # Regularization, you can keep this at the default\\nNUM_EPOCHS = 30      # Total number of training epochs (iterations over dataset)\\nSTEP_SIZE = 25       # How many epochs before decreasing learning rate (if using a step-down policy)\\nGAMMA = 0.5          # Multiplicative factor for learning rate step-down\\n\\n# 3C 3rd hyperparameters\\nBATCH_SIZE = 964     # Higher batch sizes allows for larger learning rates. An empirical heuristic suggests that, when changing\\n                     # the batch size, learning rate should change by the same factor to have comparable results\\nLR = 2e-3            # The initial Learning Rate\\nMOMENTUM = 0.9       # Hyperparameter for SGD, keep this at 0.9 when using SGD\\nWEIGHT_DECAY = 5e-5  # Regularization, you can keep this at the default\\nNUM_EPOCHS = 40      # Total number of training epochs (iterations over dataset)\\nSTEP_SIZE = 10       # How many epochs before decreasing learning rate (if using a step-down policy)\\nGAMMA = 0.5          # Multiplicative factor for learning rate step-down\\n\\n\\n# resnext101_32x8d hyperparameters\\nBATCH_SIZE = 50     # Higher batch sizes allows for larger learning rates. An empirical heuristic suggests that, when changing\\n                     # the batch size, learning rate should change by the same factor to have comparable results\\nLR = 4e-4            # The initial Learning Rate\\nMOMENTUM = 0.9       # Hyperparameter for SGD, keep this at 0.9 when using SGD\\nWEIGHT_DECAY = 5e-5  # Regularization, you can keep this at the default\\nNUM_EPOCHS = 20      # Total number of training epochs (iterations over dataset)\\nSTEP_SIZE = 18       # How many epochs before decreasing learning rate (if using a step-down policy)\\nGAMMA = 0.5          # Multiplicative factor for learning rate step-down\\n\\n# inception_v3 hyperparameters\\nBATCH_SIZE = 50     # Higher batch sizes allows for larger learning rates. An empirical heuristic suggests that, when changing\\n                     # the batch size, learning rate should change by the same factor to have comparable results\\nLR = 3e-3            # The initial Learning Rate\\nMOMENTUM = 0.9       # Hyperparameter for SGD, keep this at 0.9 when using SGD\\nWEIGHT_DECAY = 5e-5  # Regularization, you can keep this at the default\\nNUM_EPOCHS = 15      # Total number of training epochs (iterations over dataset)\\nSTEP_SIZE = 13       # How many epochs before decreasing learning rate (if using a step-down policy)\\nGAMMA = 0.5          # Multiplicative factor for learning rate step-down\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IEmMLY-wUd8n",
        "colab_type": "text"
      },
      "source": [
        "### **Create Caltech dataset (1 A/B)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LjX6UizGdU3K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pil_loader(path):\n",
        "    # open path as file to avoid ResourceWarning (https://github.com/python-pillow/Pillow/issues/835)\n",
        "    with open(path, 'rb') as f:\n",
        "        img = Image.open(f)\n",
        "        return img.convert('RGB')\n",
        "\n",
        "\n",
        "\n",
        "class Caltech(VisionDataset):\n",
        "    def __init__(self, root, split='train', transform=None, target_transform=None):\n",
        "        super(Caltech, self).__init__(root, transform=transform, target_transform=target_transform)\n",
        "\n",
        "        self.split = split \n",
        "        self.loader = pil_loader\n",
        "\n",
        "        if self.split == 'train':\n",
        "          X = read_csv(str(root).split('/')[0] + '/train.txt', sep=\"/\", header=None)\n",
        "          f = open(str(root) + '/train.txt', \"r\")\n",
        "        elif self.split == 'test':\n",
        "          X = read_csv(str(root).split('/')[0] + '/test.txt', sep=\"/\", header=None)\n",
        "          f = open(str(root) + '/test.txt', \"r\")\n",
        "\n",
        "        classes = [item for item in list(set(X[0])) if \"BACKGROUND\" not in item]\n",
        "        classes.sort()\n",
        "        class_to_idx = {classes[i]: i for i in range(len(classes))}\n",
        "\n",
        "        samples = []\n",
        "        for path in f.readlines():\n",
        "            path = path.rstrip('\\n')\n",
        "            if \"BACKGROUND\" not in path:\n",
        "                samples.append((pil_loader(root + '/101_ObjectCategories/' + path), class_to_idx[path.split(\"/\")[0]]))\n",
        "                \n",
        "\n",
        "        self.samples = samples\n",
        "        self.classes = classes\n",
        "        self.class_to_idx = class_to_idx \n",
        "        self.labels = list(class_to_idx.values())\n",
        "        f.close()\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        '''\n",
        "        __getitem__ should access an element through its index\n",
        "        Args:\n",
        "            index (int): Index\n",
        "\n",
        "        Returns:\n",
        "            tuple: (sample, target) where target is class_index of the target class.\n",
        "        '''\n",
        "\n",
        "        image, label = self.samples[index]\n",
        "\n",
        "        # Applies preprocessing when accessing the image\n",
        "        if self.transform is not None:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "    def __len__(self):\n",
        "        '''\n",
        "        The __len__ method returns the length of the dataset\n",
        "        It is mandatory, as this is used by several other components\n",
        "        '''\n",
        "        length = len(self.samples) # Provide a way to get the length (number of elements) of the dataset\n",
        "        return length"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gwii0TBHvzh",
        "colab_type": "text"
      },
      "source": [
        "### **Define data pre-processing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Yxi_BrSQcE3N",
        "colab": {}
      },
      "source": [
        "# Initial transforms\n",
        "# Define transforms for the evaluation phase\n",
        "eval_transform = transforms.Compose([transforms.Resize(320),\n",
        "                                      transforms.CenterCrop(299),\n",
        "                                      transforms.ToTensor(),\n",
        "                                      transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))                                    \n",
        "])\n",
        "\n",
        "# Define transforms for the validation phase\n",
        "valid_transform = transforms.Compose([transforms.Resize(320),\n",
        "                                  transforms.CenterCrop(299),\n",
        "                                  transforms.ToTensor(),\n",
        "                                  transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
        "])\n",
        "\n",
        "# Define transforms for the train phase\n",
        "train_transform = transforms.Compose([transforms.Resize(320), \n",
        "                                  transforms.CenterCrop(299),\n",
        "                                  transforms.ToTensor(),\n",
        "                                  transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
        "])\n",
        "\n",
        "\n",
        "# 4A, only with alexnet\n",
        "# Define transforms for the data augmentation (for the train)\n",
        "first = transforms.Compose([transforms.Resize(256),\n",
        "                              transforms.CenterCrop(224),\n",
        "                              transforms.RandomHorizontalFlip(),\n",
        "                              transforms.ToTensor(),\n",
        "                              transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
        "    ])\n",
        "\n",
        "\n",
        "second = transforms.Compose([transforms.Resize(256),\n",
        "                              transforms.CenterCrop(224),\n",
        "                              transforms.RandomVerticalFlip(),\n",
        "                              transforms.RandomPerspective(),\n",
        "                              transforms.ToTensor(),\n",
        "                              transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
        "    ])\n",
        "\n",
        "\n",
        "third = transforms.Compose([transforms.Resize(256), transforms.CenterCrop(224), \n",
        "                            transforms.RandomRotation(180), transforms.RandomVerticalFlip(),\n",
        "                            transforms.RandomHorizontalFlip(), transforms.RandomPerspective(),\n",
        "                            transforms.ToTensor(), transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
        "                            ])\n",
        "\n",
        "\n",
        "\n",
        "# Info for various settings change\n",
        "# Default: Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "# With pretrained nets: Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
        "# With inception_v3 net: Resize(320) and CenterCrop(299) because it has 299x299 input\n",
        "# With others net: Resize(256) and CenterCrop(224) because they have 224x224 input"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qYIHPzYLY7i",
        "colab_type": "text"
      },
      "source": [
        "### **Prepare Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QfVq_uDHLbsR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Clone github repository with data\n",
        "if not os.path.isdir('./Homework2-Caltech101'):\n",
        "  !git clone https://github.com/MachineLearning2020/Homework2-Caltech101.git\n",
        "\n",
        "DATA_DIR = 'Homework2-Caltech101'\n",
        "\n",
        "# Load the dataset with the default transform (on Data Augmentation, modify transform before the training loop as written below)\n",
        "dataset = Caltech(DATA_DIR, transform=train_transform)\n",
        "\n",
        "# Creating data indices for training and validation splits\n",
        "train_indices = [idx for idx in range(len(dataset)) if idx % 2]\n",
        "val_indices = [idx for idx in range(len(dataset)) if not idx % 2]\n",
        "\n",
        "# Creating data samplers that will pass to the Dataloader only the selected indexes\n",
        "train_sampler = SubsetRandomSampler(train_indices)\n",
        "valid_sampler = SubsetRandomSampler(val_indices)\n",
        "\n",
        "# Load the test set\n",
        "test_dataset = Caltech(DATA_DIR, split='test', transform=eval_transform)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYEDQ7Z21ldN",
        "colab_type": "text"
      },
      "source": [
        "### **Prepare Dataloaders**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VriRw8SI1nle",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Dataloaders iterate over pytorch datasets and transparently provide useful functions (e.g. parallelization and shuffling), we use them pinned into the CUDA\n",
        "\n",
        "train_dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, sampler=train_sampler, num_workers=1, pin_memory=True, drop_last=True)\n",
        "val_dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, sampler=valid_sampler, num_workers=1, pin_memory=True, drop_last=True)\n",
        "\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=1, pin_memory=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gbZ1t5Qs2z4j",
        "colab_type": "text"
      },
      "source": [
        "### **Prepare Network**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "exHUjtXa22DN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# NETs\n",
        "\n",
        "# Not trained alexnet () \n",
        "# net = alexnet()\n",
        "\n",
        "# Pretrained all\n",
        "# net = alexnet(pretrained=True)\n",
        "# net = resnext101_32x8d(pretrained=True)\n",
        "net = inception_v3(pretrained=True, aux_logits=False)\n",
        "\n",
        "\n",
        "\n",
        "# NETs MODIFICATIONS\n",
        "\n",
        "# inception_v3 & resnext10\n",
        "net.fc = nn.Linear(2048, NUM_CLASSES)\n",
        "\n",
        "# alexnet\n",
        "# net.classifier[6] = nn.Linear(4096, NUM_CLASSES)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KEyL3H_R4qCf",
        "colab_type": "text"
      },
      "source": [
        "### **Prepare Training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9sjq00G94tSc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define loss function\n",
        "criterion = nn.CrossEntropyLoss() # for classification, we use Cross Entropy\n",
        "\n",
        "# PARAMETERS TO OPTIMIZE\n",
        "\n",
        "# All the parameters (valid for every model) \n",
        "# parameters_to_optimize = net.parameters()\n",
        "\n",
        "# Only fully connected layers of alexnet \n",
        "# parameters_to_optimize = net.classifier.parameters()\n",
        "\n",
        "# Only convolutional layers of alexnet\n",
        "# parameters_to_optimize = net.features.parameters()\n",
        "\n",
        "# Only fully connected layer of resnext101\n",
        "# parameters_to_optimize = net.fc.parameters()\n",
        "\n",
        "# Only first convolutional layers and the last fully connected layer of inception_v3\n",
        "parameters_to_optimize = [{'params': net.Conv2d_1a_3x3.parameters()}, {'params': net.Conv2d_2a_3x3.parameters()},\n",
        "                           {'params': net.Conv2d_2b_3x3.parameters()}, {'params': net.Conv2d_3b_1x1.parameters()}, \n",
        "                           {'params': net.Conv2d_4a_3x3.parameters()}, {'params': net.fc.parameters()}]\n",
        "\n",
        "\n",
        "# OPTIMIZER\n",
        "\n",
        "# Adam optimizer\n",
        "# optimizer = optim.Adam(params = parameters_to_optimize, lr=LR)\n",
        "\n",
        "# SGD with momentum optimizer\n",
        "optimizer = optim.SGD(parameters_to_optimize, lr=LR, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)\n",
        "\n",
        "# Define StepLR scheduler\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=STEP_SIZE, gamma=GAMMA)\n",
        "\n",
        "# By default, everything is loaded to cpu\n",
        "net = net.to(DEVICE) # this will bring the network to GPU if DEVICE is cuda\n",
        "cudnn.benchmark # Calling this optimizes runtime\n",
        "\n",
        "\n",
        "# Early stopping implementation (uncomment in the for loop too)\n",
        "'''\n",
        "# For early stopping\n",
        "n_epochs_stop = 7\n",
        "min_val_loss = np.Inf\n",
        "best_net = None\n",
        "'''\n",
        "\n",
        "# For live plotting graphs\n",
        "liveloss = PlotLosses()\n",
        "\n",
        "# Params\n",
        "best_net_acc = None\n",
        "best_acc = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AxYUli9d9uYQ",
        "colab_type": "text"
      },
      "source": [
        "### **Train**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZcoQ5fD49yT_",
        "colab_type": "code",
        "cellView": "code",
        "outputId": "9c6bf1d4-ebea-420f-fa63-95a6e5852ec5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        }
      },
      "source": [
        "\n",
        "%%time\n",
        "\n",
        "# Start iterating over the epochs\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  \n",
        "  logs = {}  # Reset the logs for earch epoch\n",
        "  print('Starting epoch {}/{}, LR = {}'.format(epoch+1, NUM_EPOCHS, scheduler.get_lr()))\n",
        "  train_loss = 0                                                                          # Reset the sum of the losses for each epochs in train\n",
        "  valid_loss = 0                                                                          # Reset the sum of the losses for each epochs in validation\n",
        "  net.train()                                                                             # Set the net in train mode \n",
        "  running_corrects = 0                                                                    # Reset the number of correct predictions on train\n",
        "  train_dataloader.dataset.transform = train_transform                                    # Switch the transform to be used in __getitem__(): train_transform, first, second or third\n",
        "  for batch_idx, (images, target) in enumerate(train_dataloader):                         # Start the training using train dataloader batch-by-batch\n",
        "    images, target = images.to(DEVICE), target.to(DEVICE)\n",
        "    \n",
        "\n",
        "    outputs = net(images)\n",
        "    loss = criterion(outputs, target)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    _, preds = torch.max(outputs, 1)\n",
        "\n",
        "    train_loss += loss.detach() * images.size(0)                                          # Update the total training loss for this epoch\n",
        "\n",
        "    running_corrects += torch.sum(preds == target.data)                                   # Update the number of correct predictions on train for this epoch\n",
        "    if batch_idx % LOG_FREQUENCY == 0:\n",
        "      print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.4f}'.format(epoch+1, (batch_idx*BATCH_SIZE),\n",
        "                                                                     (len(train_dataloader)*BATCH_SIZE), 100*(batch_idx/len(train_dataloader)), loss.item()))\n",
        "  \n",
        "  train_acc = running_corrects.float() / (len(train_dataloader) * BATCH_SIZE)             # Retrieve the accuracy on train set for this epoch\n",
        "\n",
        "  net.train(mode=False)                                                                   # Set the net in evaluation mode\n",
        "  correct = 0                                                                             # Reset the number of correct predictions on validation\n",
        "  val_dataloader.dataset.transform = valid_transform                                      # Switch the transform to be used in __getitem__(): valid_transform\n",
        "  with torch.no_grad():\n",
        "    for data, target in val_dataloader:                                                   # Start the evaluation using validation dataloader batch-by-batch\n",
        "      data, target = data.to(DEVICE), target.to(DEVICE)\n",
        "      outputs = net(data)\n",
        "      loss = criterion(outputs, target)\n",
        "\n",
        "      valid_loss += loss.detach() * data.size(0)                                          # Update the total validation loss for this epoch\n",
        "      # Get predictions\n",
        "      _, preds = torch.max(outputs.data, 1)\n",
        "\n",
        "      # Update Corrects\n",
        "      correct += torch.sum(preds == target.data)                                          # Update the number of correct predictions on validation for this epoch\n",
        "\n",
        "  # Calculate Accuracy\n",
        "  accuracy = correct / float(len(val_dataloader) * BATCH_SIZE)                            # Retrieve the accuracy on train set for this epoch\n",
        "\n",
        "  print('\\nValidation set accuracy: {:.3f}%\\n'.format(\n",
        "      accuracy*100))\n",
        "  \n",
        "\n",
        "  \n",
        "  valid_loss = valid_loss/(len(val_dataloader)* BATCH_SIZE)                               # Compute the mean validation loss for this epoch\n",
        "  train_loss = train_loss/(len(train_dataloader) * BATCH_SIZE)                            # Compute the mean train loss for this epoch\n",
        "\n",
        "  # Log everything\n",
        "  logs['log loss'] = train_loss.item()\n",
        "  logs['val_log loss'] = valid_loss.item()\n",
        "  logs['accuracy'] = train_acc.item()\n",
        "  logs['val_accuracy'] = accuracy.item()\n",
        "\n",
        "  print('Validation mean loss: ' + str(valid_loss.item()))\n",
        "  print('Train mean loss: ' + str(train_loss.item()))\n",
        "  print('Gap (Validation - Train): ' + str(valid_loss.item() - train_loss.item()))\n",
        "\n",
        "  if accuracy.item() > best_acc:                                                          # Check for the best accuracy and possibly save it\n",
        "    best_acc = accuracy\n",
        "    best_net_acc = copy.deepcopy(net)\n",
        "\n",
        "\n",
        "  # Implementation of the early stopping mechanism\n",
        "  '''\n",
        "  # EARLY STOPPING IMPLEMENTATION\n",
        "  if valid_loss.item() < min_val_loss:\n",
        "  # Save the model\n",
        "    best_net = copy.deepcopy(net)\n",
        "    epochs_no_improve = 0\n",
        "    min_val_loss = valid_loss\n",
        "  \n",
        "  else:\n",
        "    epochs_no_improve += 1\n",
        "    # Check early stopping condition\n",
        "    if epochs_no_improve == n_epochs_stop:\n",
        "      print('Early stopping!')\n",
        "      \n",
        "      # Load in the best model\n",
        "      net = copy.deepcopy(best_net)\n",
        "  '''\n",
        "  \n",
        "  liveloss.update(logs)                                                                 # Update the logs for the plotting graph\n",
        "  if epoch % FREQDRAW == 0:\n",
        "    liveloss.draw()                                                                     # Draw every FREQDRAW the current graph situation\n",
        "\n",
        "  scheduler.step()                                                                      # Step the scheduler for the next epoch\n",
        "\n",
        "liveloss.draw()                                                                         # Draw the residual graph"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1gAAAE1CAYAAAD6akEFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nT5RgiYiIiIiI+IkSLBERERERET/5/wpGv3qukOp6AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 864x576 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "log loss:\n",
            "training   (min:    0.412, max:    3.746, cur:    0.412)\n",
            "validation (min:    0.588, max:    3.039, cur:    0.588)\n",
            "\n",
            "accuracy:\n",
            "training   (min:    0.223, max:    0.966, cur:    0.966)\n",
            "validation (min:    0.351, max:    0.915, cur:    0.915)\n",
            "CPU times: user 3min 58s, sys: 2min 25s, total: 6min 24s\n",
            "Wall time: 7min 42s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UsHFI-GAJd69",
        "colab_type": "text"
      },
      "source": [
        "### **Test**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EO3HV5pqJg1o",
        "colab_type": "code",
        "outputId": "966857e5-aa9c-4d6f-e430-6d446f29a80e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "net = None\n",
        "best_net = None\n",
        "net = best_net_acc.to(DEVICE) # this will bring the network to GPU if DEVICE is cuda\n",
        "net.train(False) # Set Network to evaluation mode\n",
        "\n",
        "running_corrects = 0\n",
        "for images, labels in tqdm(test_dataloader):\n",
        "  images = images.to(DEVICE)\n",
        "  labels = labels.to(DEVICE)\n",
        "\n",
        "  # Forward Pass\n",
        "  outputs = net(images)\n",
        "\n",
        "  # Get predictions\n",
        "  _, preds = torch.max(outputs.data, 1)\n",
        "\n",
        "  # Update Corrects\n",
        "  running_corrects += torch.sum(preds == labels.data).data.item()\n",
        "\n",
        "# Calculate Accuracy\n",
        "accuracy = running_corrects / float(len(test_dataloader.dataset))\n",
        "\n",
        "print('Test Accuracy: {}'.format(accuracy))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 58/58 [00:08<00:00,  7.11it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy: 0.9104735568613895\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}